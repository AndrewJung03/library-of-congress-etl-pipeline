[2025-12-07 18:27:50] [fetch_from_api] [INFO] — Starting API fetch for collection='newspapers', max_pages=2
[2025-12-07 18:27:50] [fetch_from_api] [INFO] — Fetching page 1: https://www.loc.gov/newspapers/?fo=json
[2025-12-07 18:27:55] [fetch_from_api] [INFO] — Retrieved 40 results on page 1
[2025-12-07 18:27:55] [fetch_from_api] [INFO] — Fetching page 2: https://www.loc.gov/newspapers/?fo=json&sp=2
[2025-12-07 18:27:56] [fetch_from_api] [INFO] — Retrieved 40 results on page 2
[2025-12-07 18:27:56] [fetch_from_api] [INFO] — Saved 80 total records to data/raw/newspapers_raw.json
[2025-12-07 18:27:56] [json_to_csv] [INFO] — Starting JSON → CSV conversion: data/raw/newspapers_raw.json
[2025-12-07 18:27:56] [json_to_csv] [INFO] — Ensured processed directory exists: data/processed
[2025-12-07 18:27:56] [json_to_csv] [INFO] — Loaded JSON file successfully: data/raw/newspapers_raw.json
[2025-12-07 18:27:56] [json_to_csv] [INFO] — Preparing to write CSV to: data/processed/newspapers.csv
[2025-12-07 18:27:56] [json_to_csv] [INFO] — Successfully wrote CSV file: data/processed/newspapers.csv
[2025-12-07 18:27:56] [json_to_csv] [INFO] — CSV created at: data/processed/newspapers.csv
[2025-12-07 18:27:58] [db_setup] [INFO] — Starting table drop + recreate process...
[2025-12-07 18:27:58] [db_setup] [INFO] — Attempting database connection...
[2025-12-07 18:27:58] [db_setup] [INFO] — Database connection successful.
[2025-12-07 18:27:58] [db_setup] [INFO] — Dropping existing tables...
[2025-12-07 18:27:58] [db_setup] [INFO] — Creating tables...
[2025-12-07 18:27:58] [db_setup] [INFO] — All table changes committed to database.
[2025-12-07 18:27:58] [db_setup] [INFO] — All tables dropped and recreated successfully.
[2025-12-07 18:27:59] [load_into_db] [INFO] — Starting LOAD step from cleaned CSV → Postgres.
[2025-12-07 18:27:59] [load_into_db] [INFO] — Loaded cleaned CSV: data/cleaned/newspapers_cleaned.csv (80 rows)
[2025-12-07 18:27:59] [load_into_db] [INFO] — Attempting database connection for load step...
[2025-12-07 18:27:59] [load_into_db] [INFO] — Database connection successful.
[2025-12-07 18:27:59] [load_into_db] [INFO] — Populating newspapers table...
[2025-12-07 18:27:59] [load_into_db] [INFO] — "newspapers" table populated.
[2025-12-07 18:27:59] [load_into_db] [INFO] — Populating locations table...
[2025-12-07 18:27:59] [load_into_db] [INFO] — "locations" table populated.
[2025-12-07 18:27:59] [load_into_db] [INFO] — Populating issues table...
[2025-12-07 18:27:59] [load_into_db] [INFO] — "issues" table populated.
[2025-12-07 18:27:59] [load_into_db] [INFO] — Populating languages + issue_languages tables...
[2025-12-07 18:27:59] [load_into_db] [INFO] — "language" table populated.
[2025-12-07 18:27:59] [load_into_db] [INFO] — Populating subjects + issue_subjects tables...
[2025-12-07 18:27:59] [load_into_db] [INFO] — Finished inserting all cleaned data into Postgres.
[2025-12-07 18:28:00] [charts] [INFO] — Generating chart: issues_per_year
[2025-12-07 18:28:00] [charts] [INFO] — Running SQL query:
SELECT
        EXTRACT(YEAR FROM date_issued)::INT AS year,
        COUNT(*) AS issue_count
    FROM issues
    GROUP BY year
    ORDER BY year;...
[2025-12-07 18:28:00] [charts] [INFO] — Connecting to database for chart queries...
[2025-12-07 18:28:00] [charts] [INFO] — Database connection successful.
[2025-12-07 18:28:00] [charts] [INFO] — Query returned 60 rows.
[2025-12-07 18:28:00] [charts] [INFO] — Chart saved: issues_per_year.png
[2025-12-07 18:28:00] [charts] [INFO] — Generating chart: issues_per_state
[2025-12-07 18:28:00] [charts] [INFO] — Running SQL query:
SELECT
            l.state,
            COUNT(i.issue_id) AS issue_count
        FROM issues i
        JOIN locations l ON i.location_id = l.location_id
        GROUP BY l.state
        ORDER BY issue...
[2025-12-07 18:28:00] [charts] [INFO] — Connecting to database for chart queries...
[2025-12-07 18:28:00] [charts] [INFO] — Database connection successful.
[2025-12-07 18:28:00] [charts] [INFO] — Query returned 37 rows.
[2025-12-07 18:28:01] [charts] [INFO] — Chart saved: issues_per_state.png
[2025-12-07 18:28:01] [charts] [INFO] — Generating chart: language_frequency
[2025-12-07 18:28:01] [charts] [INFO] — Running SQL query:
SELECT
            l.name AS language,
            COUNT(il.issue_id) AS issue_count
        FROM languages l
        JOIN issue_languages il ON l.language_id = il.language_id
        GROUP BY l.name
...
[2025-12-07 18:28:01] [charts] [INFO] — Connecting to database for chart queries...
[2025-12-07 18:28:01] [charts] [INFO] — Database connection successful.
[2025-12-07 18:28:01] [charts] [INFO] — Query returned 9 rows.
[2025-12-07 18:28:01] [charts] [INFO] — Chart saved: language_frequency.png
[2025-12-07 18:28:01] [charts] [INFO] — Generating chart: pages_per_issue
[2025-12-07 18:28:01] [charts] [INFO] — Running SQL query:
SELECT
            REGEXP_REPLACE(medium, '[^0-9]', '', 'g')::INT AS page_count
        FROM issues
        WHERE medium IS NOT NULL
          AND REGEXP_REPLACE(medium, '[^0-9]', '', 'g') ~ '^[0-9]+$...
[2025-12-07 18:28:01] [charts] [INFO] — Connecting to database for chart queries...
[2025-12-07 18:28:01] [charts] [INFO] — Database connection successful.
[2025-12-07 18:28:01] [charts] [INFO] — Query returned 80 rows.
[2025-12-07 18:28:01] [charts] [INFO] — Chart saved: pages_per_issue.png
[2025-12-07 18:30:12] [fetch_from_api] [INFO] — Starting API fetch for collection='newspapers', max_pages=2
[2025-12-07 18:30:12] [fetch_from_api] [INFO] — Fetching page 1: https://www.loc.gov/newspapers/?fo=json
[2025-12-07 18:30:13] [fetch_from_api] [INFO] — Retrieved 40 results on page 1
[2025-12-07 18:30:13] [fetch_from_api] [INFO] — Fetching page 2: https://www.loc.gov/newspapers/?fo=json&sp=2
[2025-12-07 18:30:13] [fetch_from_api] [INFO] — Retrieved 40 results on page 2
[2025-12-07 18:30:13] [fetch_from_api] [INFO] — Saved 80 total records to data/raw/newspapers_raw.json
[2025-12-07 18:30:13] [json_to_csv] [INFO] — Starting JSON → CSV conversion: data/raw/newspapers_raw.json
[2025-12-07 18:30:13] [json_to_csv] [INFO] — Ensured processed directory exists: data/processed
[2025-12-07 18:30:13] [json_to_csv] [INFO] — Loaded JSON file successfully: data/raw/newspapers_raw.json
[2025-12-07 18:30:13] [json_to_csv] [INFO] — Preparing to write CSV to: data/processed/newspapers.csv
[2025-12-07 18:30:13] [json_to_csv] [INFO] — Successfully wrote CSV file: data/processed/newspapers.csv
[2025-12-07 18:30:13] [json_to_csv] [INFO] — CSV created at: data/processed/newspapers.csv
[2025-12-07 18:30:14] [clean_csv] [INFO] — Starting cleaning process for RAW CSV.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Loaded raw CSV 'data/processed/newspapers.csv' with 80 rows.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Rows before cleaning: 80
[2025-12-07 18:30:14] [clean_csv] [INFO] — Removed 0 duplicate ID rows.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Filled 1 missing 'image_url' fields with 'unknown'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Applied lowercase operation on 80 values for 'title'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Applied lowercase operation on 80 values for 'description'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Applied lowercase operation on 80 values for 'language'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Applied lowercase operation on 80 values for 'subject'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Applied lowercase operation on 80 values for 'location_city'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Applied lowercase operation on 80 values for 'location_state'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Applied lowercase operation on 80 values for 'location_country'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Applied lowercase operation on 80 values for 'item_medium'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Applied lowercase operation on 80 values for 'item_language'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Applied lowercase operation on 80 values for 'item_created_published'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Applied lowercase operation on 80 values for 'item_newspaper_title'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Applied lowercase operation on 80 values for 'item_place_of_publication'.
[2025-12-07 18:30:14] [clean_csv] [INFO] — Saved cleaned CSV → data/cleaned/newspapers_cleaned.csv
[2025-12-07 18:30:14] [clean_csv] [INFO] — Saved rejected CSV → data/cleaned/newspapers_rejected.csv
[2025-12-07 18:30:14] [clean_csv] [INFO] — Cleaning pipeline completed successfully.
[2025-12-07 18:30:15] [db_setup] [INFO] — Starting table drop + recreate process...
[2025-12-07 18:30:15] [db_setup] [INFO] — Attempting database connection...
[2025-12-07 18:30:15] [db_setup] [INFO] — Database connection successful.
[2025-12-07 18:30:15] [db_setup] [INFO] — Dropping existing tables...
[2025-12-07 18:30:15] [db_setup] [INFO] — Creating tables...
[2025-12-07 18:30:15] [db_setup] [INFO] — All table changes committed to database.
[2025-12-07 18:30:15] [db_setup] [INFO] — All tables dropped and recreated successfully.
[2025-12-07 18:30:16] [load_into_db] [INFO] — Starting LOAD step from cleaned CSV → Postgres.
[2025-12-07 18:30:16] [load_into_db] [INFO] — Loaded cleaned CSV: data/cleaned/newspapers_cleaned.csv (80 rows)
[2025-12-07 18:30:16] [load_into_db] [INFO] — Attempting database connection for load step...
[2025-12-07 18:30:16] [load_into_db] [INFO] — Database connection successful.
[2025-12-07 18:30:16] [load_into_db] [INFO] — Populating newspapers table...
[2025-12-07 18:30:16] [load_into_db] [INFO] — "newspapers" table populated.
[2025-12-07 18:30:16] [load_into_db] [INFO] — Populating locations table...
[2025-12-07 18:30:16] [load_into_db] [INFO] — "locations" table populated.
[2025-12-07 18:30:16] [load_into_db] [INFO] — Populating issues table...
[2025-12-07 18:30:16] [load_into_db] [INFO] — "issues" table populated.
[2025-12-07 18:30:16] [load_into_db] [INFO] — Populating languages + issue_languages tables...
[2025-12-07 18:30:16] [load_into_db] [INFO] — "language" table populated.
[2025-12-07 18:30:16] [load_into_db] [INFO] — Populating subjects + issue_subjects tables...
[2025-12-07 18:30:16] [load_into_db] [INFO] — Finished inserting all cleaned data into Postgres.
[2025-12-07 18:30:17] [charts] [INFO] — Generating chart: issues_per_year
[2025-12-07 18:30:17] [charts] [INFO] — Running SQL query:
SELECT
        EXTRACT(YEAR FROM date_issued)::INT AS year,
        COUNT(*) AS issue_count
    FROM issues
    GROUP BY year
    ORDER BY year;...
[2025-12-07 18:30:17] [charts] [INFO] — Connecting to database for chart queries...
[2025-12-07 18:30:17] [charts] [INFO] — Database connection successful.
[2025-12-07 18:30:17] [charts] [INFO] — Query returned 60 rows.
[2025-12-07 18:30:18] [charts] [INFO] — Chart saved: issues_per_year.png
[2025-12-07 18:30:18] [charts] [INFO] — Generating chart: issues_per_state
[2025-12-07 18:30:18] [charts] [INFO] — Running SQL query:
SELECT
            l.state,
            COUNT(i.issue_id) AS issue_count
        FROM issues i
        JOIN locations l ON i.location_id = l.location_id
        GROUP BY l.state
        ORDER BY issue...
[2025-12-07 18:30:18] [charts] [INFO] — Connecting to database for chart queries...
[2025-12-07 18:30:18] [charts] [INFO] — Database connection successful.
[2025-12-07 18:30:18] [charts] [INFO] — Query returned 37 rows.
[2025-12-07 18:30:18] [charts] [INFO] — Chart saved: issues_per_state.png
[2025-12-07 18:30:18] [charts] [INFO] — Generating chart: language_frequency
[2025-12-07 18:30:18] [charts] [INFO] — Running SQL query:
SELECT
            l.name AS language,
            COUNT(il.issue_id) AS issue_count
        FROM languages l
        JOIN issue_languages il ON l.language_id = il.language_id
        GROUP BY l.name
...
[2025-12-07 18:30:18] [charts] [INFO] — Connecting to database for chart queries...
[2025-12-07 18:30:18] [charts] [INFO] — Database connection successful.
[2025-12-07 18:30:18] [charts] [INFO] — Query returned 9 rows.
[2025-12-07 18:30:18] [charts] [INFO] — Chart saved: language_frequency.png
[2025-12-07 18:30:18] [charts] [INFO] — Generating chart: pages_per_issue
[2025-12-07 18:30:18] [charts] [INFO] — Running SQL query:
SELECT
            REGEXP_REPLACE(medium, '[^0-9]', '', 'g')::INT AS page_count
        FROM issues
        WHERE medium IS NOT NULL
          AND REGEXP_REPLACE(medium, '[^0-9]', '', 'g') ~ '^[0-9]+$...
[2025-12-07 18:30:18] [charts] [INFO] — Connecting to database for chart queries...
[2025-12-07 18:30:18] [charts] [INFO] — Database connection successful.
[2025-12-07 18:30:18] [charts] [INFO] — Query returned 80 rows.
[2025-12-07 18:30:18] [charts] [INFO] — Chart saved: pages_per_issue.png
